{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_hy9iCXlaax"
   },
   "source": [
    "# CNN Transfer Learning on Cats-Dogs Classification\n",
    "\n",
    "## CIML Summer Institute, UC San Diego\n",
    "\n",
    "VGG16 trained on ImageNet data is used as a pre-trained model from which to extract features. Features are then passed through fully connected layers to classify cats vs. dogs.\n",
    "\n",
    "Adapted from tensorflow tutorials\n",
    "(https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NmDHijos0sW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjRHT_7ds0sX",
    "outputId": "67d5215b-c5a4-47fa-ee1e-4f13177ec0c7"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow version:\",tf.__version__)\n",
    "!python --version\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5OAYvK0s0sX"
   },
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd4JjV5Cs0sX"
   },
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 1234\n",
    "\n",
    "# Disable hash randomization by specifying the value 0.\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set python built-in random generator\n",
    "random.seed(seed)\n",
    "\n",
    "# Set tf global random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set tensorflow graph-level random seed\n",
    "tf.compat.v1.random.set_random_seed(seed)\n",
    "\n",
    "# Potential randomness from CUDNN\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLToN9Hxs0sY"
   },
   "source": [
    "### Set image dimensions, location of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions \n",
    "img_width, img_height = <<FILL-IN>> , <<FILL-IN>> \n",
    "IMG_SIZE = (img_width,img_height) #image size (150,150)\n",
    "IMG_SHAPE = IMG_SIZE + (<<FILL-IN>> ,) #image shape(3,150,150)\n",
    "\n",
    "# Location of images\n",
    "train_data_dir = <<FILL-IN>>\n",
    "validation_data_dir = <<FILL-IN>>\n",
    "test_data_dir = <<FILL-IN>>\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = <<FILL-IN>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation setup\n",
    "datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = datagen.flow_from_directory(train_data_dir,target_size=<<FILL-IN>>, # img size we defined above\n",
    "                                              batch_size = <<FILL-IN>> , class_mode='binary', # batch size we defined above \n",
    "                                              shuffle = True, seed = <<FILL-IN>>)   # seed we defined above           \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = datagen.flow_from_directory(<<FILL-IN>>,target_size=<<FILL-IN>>,\n",
    "                                                   batch_size = <<FILL-IN>>,class_mode=<<FILL-IN>>,\n",
    "                                                   shuffle = <<FILL-IN>>, seed = <<FILL-IN>>) # no need to shuffle val data\n",
    "# Set up generator to generate batched of test data for model\n",
    "test_generator = datagen.flow_from_directory(<<FILL-IN>>, target_size=<<FILL-IN>>,\n",
    "                                             batch_size = <<FILL-IN>>, class_mode=<<FILL-IN>>,\n",
    "                                             shuffle = <<FILL-IN>>, seed = <<FILL-IN>>) # no need to shuffle test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model's Imagenet weights not including the top fully connected layers\n",
    "\n",
    "base_model = applications.VGG16(include_top = <<FILL-IN>>, # don't include top https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16\n",
    "                                weights = <<FILL-IN>>, #use Imagenet weights\n",
    "                                input_shape=IMG_SHAPE) \n",
    "# Freeze all weights of VGG16 model\n",
    "base_model.trainable = <<FILL-IN>>\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top model\n",
    "\n",
    "Create fully connected layers to put on top of pre-trained VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(<<FILL-IN>>, activation=<<FILL-IN>>)) #add Dense layer with 256 units and relu activation https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "model.add(Dropout(<<FILL-IN>>)) #apply 50% dropout rate. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "Train weights in top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Compile model with Adam optimizer with slow learning rate,\n",
    "# Binary Cross-Entropy loss function and Accuracy metric\n",
    "model.compile(optimizer= <<FILL-IN>>, #use Adam optimizer with 0.0001 learning rate https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "              loss= <<FILL-IN>>, #use default Binary Cross-entropy loss https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
    "              metrics=[<<FILL-IN>>]) #use accuracy metrics; this will be printed out during training in each epochs https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\n",
    "\n",
    "# Early Stopping to avoid overfitting and ModelCheckpoint to save the best model\n",
    "checkpoint_path = 'tmp/checkpoint'\n",
    "callbacks = [EarlyStopping(monitor=<<FILL-IN>>,patience=3,min_delta=0.001, #use val_loss to monitor during training https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "                           mode=<<FILL-IN>>), # we want to minimize val_loss\n",
    "             ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                             mode = 'min', save_best_only = True, \n",
    "                             save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "train_history = model.<<FILL-IN>>(train_generator,epochs=EPOCHS, #train the model using model.fit()\n",
    "                          validation_data=validation_generator, \n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model that was saved using ModelCheckpoint\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights \n",
    "model.save(\"weights_from_feature_extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation history\n",
    "fig, axs = plt.subplots(1,2, figsize= (20,5))\n",
    "axs[0].plot(train_history.history['loss'])\n",
    "axs[0].plot(train_history.history['val_loss'])\n",
    "axs[0].set_title(\"Train, Val loss history\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].legend([\"Train Loss\",\"Val Loss\"])\n",
    "\n",
    "axs[1].plot(train_history.history['accuracy'])\n",
    "axs[1].plot(train_history.history['val_accuracy'])\n",
    "axs[1].set_title(\"Train, Val Accuracy history\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend([\"Train Accuracy\",\"Val Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_accuracy = model.evaluate(train_generator)\n",
    "print(\"Train data accuracy:\", train_accuracy)\n",
    "\n",
    "_, test_accuracy = <<FILL-IN>> ## evaluate test data\n",
    "print(\"Test data accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted value and the ground truth value of test data\n",
    "pred = model.predict_classes(test_generator)\n",
    "true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for test data\n",
    "print(classification_report(y_true= true, y_pred = pred, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(img_file):\n",
    "    img = load_img(img_file, target_size = (img_width, img_height))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = img_to_array(img) / 255\n",
    "    img = np.expand_dims(img, axis = 0) #model input is (1,150,150,3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader('data/catsVsDogs/test/cats/cat.1070.jpg')\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader('data/catsVsDogs/test/dogs/dog.1233.jpg')\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader('data/catsVsDogs/test/cats/cat.1195.jpg')\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "features_final_soln_tfl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
